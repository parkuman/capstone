{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.utils import extract_mfcc, add_padding, extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEAKERS: ['hannah', 'aiden', 'parker', 'adam']\n",
      "Max Files to Extract: 1239\n",
      "Starting Extraction\n",
      "=================================| Extracting features for speaker: hannah |=================================\n",
      "=================================| Extracting features for speaker: aiden |=================================\n",
      "=================================| Extracting features for speaker: parker |=================================\n",
      "=================================| Extracting features for speaker: adam |=================================\n",
      " Done Extraction!1239 / 1239)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directory = \"training_data_browser\"\n",
    "speakers = os.listdir(directory)\n",
    "features = []\n",
    "labels = []\n",
    "duration = 1000 # ms - duration of the split audio clip in ms\n",
    "frames_max = 0\n",
    "\n",
    "min_class_count = 0\n",
    "for speaker in speakers:\n",
    "    num_files_for_speaker = len(os.listdir(directory + \"/\" + speaker))\n",
    "\n",
    "    if num_files_for_speaker < min_class_count or min_class_count == 0:\n",
    "        min_class_count = num_files_for_speaker\n",
    "\n",
    "\n",
    "print(\"SPEAKERS: \" + str(speakers))\n",
    "print(\"Max Files to Extract: \" + str(min_class_count))\n",
    "\n",
    "print(\"Starting Extraction\")\n",
    "for speaker in speakers:\n",
    "    file_count = 0\n",
    "    print(\"=================================| Extracting features for speaker: \" + speaker + \" |=================================\")\n",
    "    for file in os.listdir(directory + \"/\" + speaker):\n",
    "        print(f\"processing file ({file_count} / {min_class_count})\", end=\"\\r\")\n",
    "\n",
    "        # only process the smallest class count\n",
    "        if file_count >= min_class_count:\n",
    "            break\n",
    "\n",
    "        file_count +=1 \n",
    "\n",
    "        file_path = directory + \"/\" + speaker + \"/\" + file\n",
    "        \n",
    "        y, sr = librosa.load(file_path)\n",
    "        label = speakers.index(speaker)\n",
    "\n",
    "        normalized_y = librosa.util.normalize(y)\n",
    "        mfcc = extract_features(normalized_y, sr)\n",
    "\n",
    "        features.append(mfcc)\n",
    "        labels.append(label)\n",
    "            \n",
    "print(\" Done Extraction!\\n\")\n",
    "\n",
    "\n",
    "# for speaker in speakers:\n",
    "#     print(\"=================================| Extracting features for speaker: \" + speaker + \" |=================================\")\n",
    "#     for file in os.listdir(directory + \"/\" + speaker):\n",
    "#         file_path = directory + \"/\" + speaker + \"/\" + file\n",
    "#         print(\"[\" + file_path + \"]\\n Splitting up audio and extracting features\", end=\"\")\n",
    "        \n",
    "#         sr = librosa.get_samplerate(file_path)\n",
    "#         stream = librosa.stream(file_path,\n",
    "#                                 block_length=3,                             # frames in each iteration\n",
    "#                                 frame_length=int(sr * duration / 1000),     # samples per frame\n",
    "#                                 hop_length=int(sr * duration / 1000 * 0.5)) # \"hops\" -frames will overlap if hop_length < frame_length\n",
    "        \n",
    "#         label = speakers.index(speaker)\n",
    "        \n",
    "#         for y in stream:\n",
    "#             print(\".\", end=\"\")\n",
    "\n",
    "#             y = (y - min(y)) / (np.max(y) - np.min(y))\n",
    "#             features.append(extract_features(y, sr))\n",
    "#             labels.append(label)\n",
    "            \n",
    "#             # mfccs = extract_mfcc(y, sr)\n",
    "\n",
    "#             # # add to features and labels\n",
    "#             # features.append(mfccs)\n",
    "#             # labels.append(label)\n",
    "\n",
    "#             # # keep track of the max frames extracted so we can pad later\n",
    "#             # num_frames = mfccs.shape[1]\n",
    "#             # if (num_frames > frames_max):\n",
    "#             #     frames_max = num_frames\n",
    "            \n",
    "#         print(\" Done Extraction!\\n\")\n",
    "\n",
    "\n",
    "# print(\"Padding Features... \", end=\"\")\n",
    "# padded_features = add_padding(features, frames_max)\n",
    "# print(\"Done!\\n\")\n",
    "\n",
    "# save the extracted features and labels to use later\n",
    "np.save(\"extracted_data/features\", np.array(features))\n",
    "np.save(\"extracted_data/labels\", np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b5f8c463c0031db8efa2e4d1b1a4f98a05a142dffd34560136929b16da9ba84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
